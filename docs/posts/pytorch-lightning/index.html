<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Pytorch Lightning | Xiaoyu&#39;s blog</title>
<meta name="keywords" content="tools">
<meta name="description" content="what is pytorch lightning PyTorch Lightning is the deep learning framework with “batteries included” for professional AI researchers and machine learning engineers who need maximal flexibility while super-charging performance at scale.
quick start
Your browser does not support the video tag. summary steps:
lightning module forward func configure optimizers def training_step def validation_step remove .cuda() backward and step as hook init lightning module init trainer add other functions as call back explanation about dataloader and sampler LightningDataModule was designed as a way of decoupling data-related hooks from the LightningDataModule, so you can develop dataset agonostic models.">
<meta name="author" content="">
<link rel="canonical" href="https://x423xu.github.io/posts/pytorch-lightning/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css" integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://x423xu.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://x423xu.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://x423xu.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://x423xu.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://x423xu.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            processEscapes: true,
            processEnvironments: true
        },
        options: {
            skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    };

    window.addEventListener('load', (event) => {
        document.querySelectorAll("mjx-container").forEach(function (x) {
            x.parentElement.classList += 'has-jax'
        })
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<meta property="og:title" content="Pytorch Lightning" />
<meta property="og:description" content="what is pytorch lightning PyTorch Lightning is the deep learning framework with “batteries included” for professional AI researchers and machine learning engineers who need maximal flexibility while super-charging performance at scale.
quick start
Your browser does not support the video tag. summary steps:
lightning module forward func configure optimizers def training_step def validation_step remove .cuda() backward and step as hook init lightning module init trainer add other functions as call back explanation about dataloader and sampler LightningDataModule was designed as a way of decoupling data-related hooks from the LightningDataModule, so you can develop dataset agonostic models." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://x423xu.github.io/posts/pytorch-lightning/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-31T16:43:31-04:00" />
<meta property="article:modified_time" content="2022-10-31T16:43:31-04:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Pytorch Lightning"/>
<meta name="twitter:description" content="what is pytorch lightning PyTorch Lightning is the deep learning framework with “batteries included” for professional AI researchers and machine learning engineers who need maximal flexibility while super-charging performance at scale.
quick start
Your browser does not support the video tag. summary steps:
lightning module forward func configure optimizers def training_step def validation_step remove .cuda() backward and step as hook init lightning module init trainer add other functions as call back explanation about dataloader and sampler LightningDataModule was designed as a way of decoupling data-related hooks from the LightningDataModule, so you can develop dataset agonostic models."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://x423xu.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Pytorch Lightning",
      "item": "https://x423xu.github.io/posts/pytorch-lightning/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Pytorch Lightning",
  "name": "Pytorch Lightning",
  "description": "what is pytorch lightning PyTorch Lightning is the deep learning framework with “batteries included” for professional AI researchers and machine learning engineers who need maximal flexibility while super-charging performance at scale.\nquick start\nYour browser does not support the video tag. summary steps:\nlightning module forward func configure optimizers def training_step def validation_step remove .cuda() backward and step as hook init lightning module init trainer add other functions as call back explanation about dataloader and sampler LightningDataModule was designed as a way of decoupling data-related hooks from the LightningDataModule, so you can develop dataset agonostic models.",
  "keywords": [
    "tools"
  ],
  "articleBody": "what is pytorch lightning PyTorch Lightning is the deep learning framework with “batteries included” for professional AI researchers and machine learning engineers who need maximal flexibility while super-charging performance at scale.\nquick start\nYour browser does not support the video tag. summary steps:\nlightning module forward func configure optimizers def training_step def validation_step remove .cuda() backward and step as hook init lightning module init trainer add other functions as call back explanation about dataloader and sampler LightningDataModule was designed as a way of decoupling data-related hooks from the LightningDataModule, so you can develop dataset agonostic models. The LightningDataModule makes it easy to hot swap different Datasets with your model, so you can test it and benchmark it across domains. It also makes sharing and resuing the exact data splits and transforms across projects possible.\nLIGHTNINGDATAMODULE Your browser does not support the video tag. A datamodule encapsulates the five steps involved in data preprocessing in Pytorch:\nDownload/tokenize/process Clean and save to disk Load inside Dataset Apply transforms Wrap inside a dataloader The class can then be shared and used anywhere\n1 2 3 4 5 6 7 8 9 10 from pl_bolts.datamodules import CIFAR10DataModule, ImagenetDataModule model = LitClassifier() trainer = Trainer() imagenet = ImagenetDataModule() trainer.fit(model, datamodule=imagenet) cifar10 = CIFAR10DataModule() trainer.fit(model, datamodule=cifar10) why do i need a DataModule In normal pytorch code, the data cleaning or preparation is usually scattered across many files. This makes sharing and reusing the exact splits and transforms across projects impossible.\nThe DataModule solves following questions:\nwhat splists did you use? what transforms did you use? what normalization did you use? how did you prepare/tokenize the data? what is a DataModule A DataModule is simply a collection of a train_dataloader, val_dataloader, test_dataloader and predict_dataloader along with the matching transforms and data precessing/downloads steps required.\na simply pytorch example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 # regular PyTorch test_data = MNIST(my_path, train=False, download=True) predict_data = MNIST(my_path, train=False, download=True) train_data = MNIST(my_path, train=True, download=True) train_data, val_data = random_split(train_data, [55000, 5000]) train_loader = DataLoader(train_data, batch_size=32) val_loader = DataLoader(val_data, batch_size=32) test_loader = DataLoader(test_data, batch_size=32) predict_loader = DataLoader(predict_data, batch_size=32) # Datamodule class MNISTDataModule(pl.LightningDataModule): def __init__(self, data_dir: str = \"path/to/dir\", batch_size: int = 32): super().__init__() self.data_dir = data_dir self.batch_size = batch_size def setup(self, stage: Optional[str] = None): self.mnist_test = MNIST(self.data_dir, train=False) self.mnist_predict = MNIST(self.data_dir, train=False) mnist_full = MNIST(self.data_dir, train=True) self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000]) def train_dataloader(self): return DataLoader(self.mnist_train, batch_size=self.batch_size) def val_dataloader(self): return DataLoader(self.mnist_val, batch_size=self.batch_size) def test_dataloader(self): return DataLoader(self.mnist_test, batch_size=self.batch_size) def predict_dataloader(self): return DataLoader(self.mnist_predict, batch_size=self.batch_size) def teardown(self, stage: Optional[str] = None): # Used to clean-up when the run is finished ... As the complexity of the preprocessing grows (transforms, multiple-GPU training), you can let lightning handle those details for you while making this dataset reusable so you can share with collegues or use in different projects. 1 2 3 4 5 mnist = MNISTDataModule(my_path) model = LitClassifier() trainer = Trainer() trainer.fit(model, mnist) a more realistic DataModule with reusability 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 import pytorch_lightning as pl from torch.utils.data import random_split, DataLoader # Note - you must have torchvision installed for this example from torchvision.datasets import MNIST from torchvision import transforms class MNISTDataModule(pl.LightningDataModule): def __init__(self, data_dir: str = \"./\"): super().__init__() self.data_dir = data_dir self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]) def prepare_data(self): # download MNIST(self.data_dir, train=True, download=True) MNIST(self.data_dir, train=False, download=True) def setup(self, stage: Optional[str] = None): # Assign train/val datasets for use in dataloaders if stage == \"fit\" or stage is None: mnist_full = MNIST(self.data_dir, train=True, transform=self.transform) self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000]) # Assign test dataset for use in dataloader(s) if stage == \"test\" or stage is None: self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform) if stage == \"predict\" or stage is None: self.mnist_predict = MNIST(self.data_dir, train=False, transform=self.transform) def train_dataloader(self): return DataLoader(self.mnist_train, batch_size=32) def val_dataloader(self): return DataLoader(self.mnist_val, batch_size=32) def test_dataloader(self): return DataLoader(self.mnist_test, batch_size=32) def predict_dataloader(self): return DataLoader(self.mnist_predict, batch_size=32) prepare_data explanation Downloading and saving data with multiple processes will result in corrupt data. Lightning ensures the prepare_data() is called only within a single process on CPU, so you can safely add your downloading lgic within. In case of multi-node training, the execution of this hook depends upon prepare_data_per_node setup() is called after prepare_data and there is a barrier in between which ensures that all the processes proceed to setup once the data is prepared and available for use. It will only be executed once.\nsetup explanation There are also data operations you might want to perform on every GPU. Use setup() to do things like:\ncount numbers of classes build vocabulary perform train/val/test splits create datasets apply transforms etc… ",
  "wordCount" : "824",
  "inLanguage": "en",
  "datePublished": "2022-10-31T16:43:31-04:00",
  "dateModified": "2022-10-31T16:43:31-04:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://x423xu.github.io/posts/pytorch-lightning/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Xiaoyu's blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://x423xu.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class=" dark" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://x423xu.github.io/" accesskey="h" title="Xiaoyu&#39;s blog (Alt + H)">Xiaoyu&#39;s blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://x423xu.github.io/" title="home">
                    <span>home</span>
                </a>
            </li>
            <li>
                <a href="https://x423xu.github.io/archives/" title="archives">
                    <span>archives</span>
                </a>
            </li>
            <li>
                <a href="https://x423xu.github.io/categories/" title="categories">
                    <span>categories</span>
                </a>
            </li>
            <li>
                <a href="https://x423xu.github.io/tags/" title="tags">
                    <span>tags</span>
                </a>
            </li>
            <li>
                <a href="https://x423xu.github.io/search/" title="search (Alt &#43; /)" accesskey=/>
                    <span>search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://x423xu.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://x423xu.github.io/posts/">Posts</a></div>
    <h1 class="post-title">
      Pytorch Lightning
    </h1>
    <div class="post-meta"><span title='2022-10-31 16:43:31 -0400 EDT'>October 31, 2022</span>&nbsp;·&nbsp;4 min

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#what-is-pytorch-lightning" aria-label="what is pytorch lightning">what is pytorch lightning</a><ul>
                        
                <li>
                    <a href="#summary" aria-label="summary">summary</a></li></ul>
                </li>
                <li>
                    <a href="#explanation-about-dataloader-and-sampler" aria-label="explanation about dataloader and sampler">explanation about dataloader and sampler</a><ul>
                        
                <li>
                    <a href="#why-do-i-need-a-datamodule" aria-label="why do i need a DataModule">why do i need a DataModule</a></li>
                <li>
                    <a href="#what-is-a-datamodule" aria-label="what is a DataModule">what is a DataModule</a></li>
                <li>
                    <a href="#prepare_data-explanation" aria-label="prepare_data explanation">prepare_data explanation</a></li>
                <li>
                    <a href="#setup-explanation" aria-label="setup explanation">setup explanation</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="what-is-pytorch-lightning">what is pytorch lightning<a hidden class="anchor" aria-hidden="true" href="#what-is-pytorch-lightning">#</a></h1>
<p>PyTorch Lightning is the deep learning framework with “batteries included” for professional AI researchers and machine learning engineers who need maximal flexibility while super-charging performance at scale.</p>
<p><strong>quick start</strong></p>

<video width=100% controls autoplay>
    <source src="https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/pl_docs/pl_docs_animation_final.m4v" type="video/webm">
    Your browser does not support the video tag.  
</video>

<h2 id="summary">summary<a hidden class="anchor" aria-hidden="true" href="#summary">#</a></h2>
<p>steps:</p>
<ol>
<li>lightning module</li>
<li>forward func</li>
<li>configure optimizers</li>
<li>def training_step</li>
<li>def validation_step</li>
<li>remove .cuda()</li>
<li>backward and step as hook</li>
<li>init lightning module</li>
<li>init trainer</li>
<li>add other functions as call back</li>
</ol>
<h1 id="explanation-about-dataloader-and-sampler">explanation about dataloader and sampler<a hidden class="anchor" aria-hidden="true" href="#explanation-about-dataloader-and-sampler">#</a></h1>
<p><code>LightningDataModule</code> was designed as a way of decoupling data-related hooks from the <code>LightningDataModule</code>, so you can develop dataset agonostic models. The <code>LightningDataModule</code> makes it easy to hot swap different Datasets with your model, so you can test it and benchmark it across domains. It also makes sharing and resuing the exact data splits and transforms across projects possible.</p>
<p><strong>LIGHTNINGDATAMODULE</strong>

<video width=100% controls autoplay>
    <source src="https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/pl_docs/pt_dm_vid.m4v" type="video/webm">
    Your browser does not support the video tag.  
</video>
</p>
<ul>
<li>
<p>A datamodule encapsulates the five steps involved in data preprocessing in Pytorch:</p>
<ol>
<li>Download/tokenize/process</li>
<li>Clean and save to disk</li>
<li>Load inside Dataset</li>
<li>Apply transforms</li>
<li>Wrap inside a dataloader</li>
</ol>
</li>
<li>
<p>The class can then be shared and used anywhere</p>
</li>
</ul>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>    from pl_bolts.datamodules import CIFAR10DataModule, ImagenetDataModule
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    model = LitClassifier()
</span></span><span style="display:flex;"><span>    trainer = Trainer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    imagenet = ImagenetDataModule()
</span></span><span style="display:flex;"><span>    trainer.fit(model, datamodule=imagenet)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    cifar10 = CIFAR10DataModule()
</span></span><span style="display:flex;"><span>    trainer.fit(model, datamodule=cifar10)
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="why-do-i-need-a-datamodule">why do i need a DataModule<a hidden class="anchor" aria-hidden="true" href="#why-do-i-need-a-datamodule">#</a></h2>
<p>In normal pytorch code, the data cleaning or preparation is usually scattered across many files. This makes sharing and reusing the exact splits and transforms across projects impossible.</p>
<p>The DataModule solves following questions:</p>
<ul>
<li>what splists did you use?</li>
<li>what transforms did you use?</li>
<li>what normalization did you use?</li>
<li>how did you prepare/tokenize the data?</li>
</ul>
<h2 id="what-is-a-datamodule">what is a DataModule<a hidden class="anchor" aria-hidden="true" href="#what-is-a-datamodule">#</a></h2>
<p>A DataModule is simply a collection of a train_dataloader, val_dataloader, test_dataloader and predict_dataloader along with the matching transforms and data precessing/downloads steps required.</p>
<ul>
<li>a simply pytorch example:</li>
</ul>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>    # regular PyTorch
</span></span><span style="display:flex;"><span>    test_data = MNIST(my_path, train=False, download=True)
</span></span><span style="display:flex;"><span>    predict_data = MNIST(my_path, train=False, download=True)
</span></span><span style="display:flex;"><span>    train_data = MNIST(my_path, train=True, download=True)
</span></span><span style="display:flex;"><span>    train_data, val_data = random_split(train_data, [55000, 5000])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    train_loader = DataLoader(train_data, batch_size=32)
</span></span><span style="display:flex;"><span>    val_loader = DataLoader(val_data, batch_size=32)
</span></span><span style="display:flex;"><span>    test_loader = DataLoader(test_data, batch_size=32)
</span></span><span style="display:flex;"><span>    predict_loader = DataLoader(predict_data, batch_size=32)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    # Datamodule
</span></span><span style="display:flex;"><span>    class MNISTDataModule(pl.LightningDataModule):
</span></span><span style="display:flex;"><span>    def __init__(self, data_dir: str = &#34;path/to/dir&#34;, batch_size: int = 32):
</span></span><span style="display:flex;"><span>        super().__init__()
</span></span><span style="display:flex;"><span>        self.data_dir = data_dir
</span></span><span style="display:flex;"><span>        self.batch_size = batch_size
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    def setup(self, stage: Optional[str] = None):
</span></span><span style="display:flex;"><span>        self.mnist_test = MNIST(self.data_dir, train=False)
</span></span><span style="display:flex;"><span>        self.mnist_predict = MNIST(self.data_dir, train=False)
</span></span><span style="display:flex;"><span>        mnist_full = MNIST(self.data_dir, train=True)
</span></span><span style="display:flex;"><span>        self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    def train_dataloader(self):
</span></span><span style="display:flex;"><span>        return DataLoader(self.mnist_train, batch_size=self.batch_size)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    def val_dataloader(self):
</span></span><span style="display:flex;"><span>        return DataLoader(self.mnist_val, batch_size=self.batch_size)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    def test_dataloader(self):
</span></span><span style="display:flex;"><span>        return DataLoader(self.mnist_test, batch_size=self.batch_size)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    def predict_dataloader(self):
</span></span><span style="display:flex;"><span>        return DataLoader(self.mnist_predict, batch_size=self.batch_size)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    def teardown(self, stage: Optional[str] = None):
</span></span><span style="display:flex;"><span>        # Used to clean-up when the run is finished
</span></span><span style="display:flex;"><span>        ...
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>As the complexity of the preprocessing grows (transforms, multiple-GPU training), you can let lightning handle those details for you while making this dataset reusable so you can share with collegues or use in different projects.</li>
</ul>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>    mnist = MNISTDataModule(my_path)
</span></span><span style="display:flex;"><span>    model = LitClassifier()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    trainer = Trainer()
</span></span><span style="display:flex;"><span>    trainer.fit(model, mnist)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>a more realistic DataModule with reusability</li>
</ul>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>    import pytorch_lightning as pl
</span></span><span style="display:flex;"><span>    from torch.utils.data import random_split, DataLoader
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    # Note - you must have torchvision installed for this example
</span></span><span style="display:flex;"><span>    from torchvision.datasets import MNIST
</span></span><span style="display:flex;"><span>    from torchvision import transforms
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    class MNISTDataModule(pl.LightningDataModule):
</span></span><span style="display:flex;"><span>        def __init__(self, data_dir: str = &#34;./&#34;):
</span></span><span style="display:flex;"><span>            super().__init__()
</span></span><span style="display:flex;"><span>            self.data_dir = data_dir
</span></span><span style="display:flex;"><span>            self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def prepare_data(self):
</span></span><span style="display:flex;"><span>            # download
</span></span><span style="display:flex;"><span>            MNIST(self.data_dir, train=True, download=True)
</span></span><span style="display:flex;"><span>            MNIST(self.data_dir, train=False, download=True)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def setup(self, stage: Optional[str] = None):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            # Assign train/val datasets for use in dataloaders
</span></span><span style="display:flex;"><span>            if stage == &#34;fit&#34; or stage is None:
</span></span><span style="display:flex;"><span>                mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)
</span></span><span style="display:flex;"><span>                self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            # Assign test dataset for use in dataloader(s)
</span></span><span style="display:flex;"><span>            if stage == &#34;test&#34; or stage is None:
</span></span><span style="display:flex;"><span>                self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            if stage == &#34;predict&#34; or stage is None:
</span></span><span style="display:flex;"><span>                self.mnist_predict = MNIST(self.data_dir, train=False, transform=self.transform)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def train_dataloader(self):
</span></span><span style="display:flex;"><span>            return DataLoader(self.mnist_train, batch_size=32)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def val_dataloader(self):
</span></span><span style="display:flex;"><span>            return DataLoader(self.mnist_val, batch_size=32)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def test_dataloader(self):
</span></span><span style="display:flex;"><span>            return DataLoader(self.mnist_test, batch_size=32)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        def predict_dataloader(self):
</span></span><span style="display:flex;"><span>            return DataLoader(self.mnist_predict, batch_size=32)
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="prepare_data-explanation">prepare_data explanation<a hidden class="anchor" aria-hidden="true" href="#prepare_data-explanation">#</a></h2>
<p>Downloading and saving data with multiple processes will result in corrupt data. Lightning ensures the <code>prepare_data()</code> is called only within a single process on CPU, so you can safely add your downloading lgic within. In case of multi-node training,  the execution of this hook depends upon <code>prepare_data_per_node </code> <code>setup()</code> is called after <code>prepare_data</code> and there is a barrier in between which ensures that all the processes proceed to <code>setup</code> once the data is prepared and  available for use. It will only be executed once.</p>
<h2 id="setup-explanation">setup explanation<a hidden class="anchor" aria-hidden="true" href="#setup-explanation">#</a></h2>
<p>There are also data operations you might want to perform on every GPU. Use <code>setup()</code> to do things like:</p>
<ul>
<li>count numbers of classes</li>
<li>build vocabulary</li>
<li>perform train/val/test splits</li>
<li>create datasets</li>
<li>apply transforms</li>
<li>etc&hellip;</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://x423xu.github.io/tags/tools/">tools</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://x423xu.github.io/posts/debugs/">
    <span class="title">« Prev</span>
    <br>
    <span>Debugs</span>
  </a>
  <a class="next" href="https://x423xu.github.io/posts/2022-10-27-spectral-gnn/">
    <span class="title">Next »</span>
    <br>
    <span>Spectral Gnn</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Pytorch Lightning on twitter"
        href="https://twitter.com/intent/tweet/?text=Pytorch%20Lightning&amp;url=https%3a%2f%2fx423xu.github.io%2fposts%2fpytorch-lightning%2f&amp;hashtags=tools">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
</div>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2022 <a href="https://x423xu.github.io/">Xiaoyu&#39;s blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
