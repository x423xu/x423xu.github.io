---
layout: post
title: Gupta-dissertation-visual-text
date: 2022-06-01 14:41:09
---
**keywords: unsupervised, visual+text, representations**

# Challenges

## Challenge 1: Accurate and generalizable representations
1. The model learn a representation does not generalize, by overfitting.
2. Concepts such as objects, attributes, relationships or interactions are shared across vision-language tasks.
3. Such representations are multi-modal. Now separately.
### Work towards the challenge
1. Concepts of objects and attributes are shared across tasks.
2. Word-region verification sub-task by inner product.

<!-- <script src="https://kit.fontawesome.com/c7a4fc0b4e.js" crossorigin="anonymous"></script>
<i class="fa-solid fa-user"></i> -->
? Shared visual-language representations leads to a greater inductive transfer

### Using images to improve word representations
Limitations of learning only from text:
1. Text consists of intepretations of concepts, rather than description of visual appearance.
2. Single co-occurrence type, actually more than one way.

## Challenge 2: Mapping tectual references to image-regions without strong supervision.

## Challeng 3: MOdelling interactions between object

----
# Background

## Visual representations

1. Mean pooling or learned transformations for CNN features
2. Region-level representations: unsupervised [13], [14].

## Language representations

1. Word-level representations: co-occurrence
2. Sentence-level representations
3. Contextualized word representations